"""
Tests du moteur SQL - Ã‰valuation de la qualitÃ© et des performances
"""
import sys
import os
import json
import time
import re
from datetime import datetime

# Configuration des imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from app.sql_engine import generate_sql_query, execute_sql_query, ask_odoo_data

class SQLEngineTest:
    def __init__(self, test_datasets_path="tests/test_datasets.json"):
        """Initialise les tests avec le dataset"""
        with open(test_datasets_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        self.questions = data['sql_questions']
        self.results = []
        
    def evaluate_sql_quality(self, generated_sql, expected_pattern):
        """
        Ã‰value si le SQL gÃ©nÃ©rÃ© correspond au pattern attendu
        Returns: (score, details)
        """
        # Normalisation
        sql_normalized = re.sub(r'\s+', ' ', generated_sql.lower().strip())
        pattern_normalized = expected_pattern.lower()
        
        # VÃ©rification du pattern (regex)
        if re.search(pattern_normalized, sql_normalized, re.IGNORECASE):
            return 1.0, "âœ“ Pattern SQL correct"
        else:
            return 0.0, "âœ— Pattern SQL incorrect"
    
    def test_single_question(self, test_case):
        """Test une seule question"""
        question = test_case['question']
        print(f"\n{'='*70}")
        print(f"ğŸ§ª Test: {test_case['id']} - {question}")
        print(f"   CatÃ©gorie: {test_case['category']} | DifficultÃ©: {test_case['difficulty']}")
        print(f"{'='*70}")
        
        result = {
            'id': test_case['id'],
            'question': question,
            'category': test_case['category'],
            'difficulty': test_case['difficulty'],
            'timestamp': datetime.now().isoformat()
        }
        
        try:
            # 1. Mesure du temps de gÃ©nÃ©ration SQL
            start_gen = time.time()
            generated_sql = generate_sql_query(question)
            gen_time = time.time() - start_gen
            
            result['generated_sql'] = generated_sql
            result['generation_time'] = round(gen_time, 2)
            
            print(f"\nğŸ“ SQL GÃ©nÃ©rÃ© ({gen_time:.2f}s):")
            print(f"   {generated_sql}")
            
            # 2. Ã‰valuation de la qualitÃ© du SQL
            quality_score, quality_msg = self.evaluate_sql_quality(
                generated_sql, 
                test_case['expected_sql_pattern']
            )
            result['quality_score'] = quality_score
            result['quality_message'] = quality_msg
            
            print(f"\nğŸ¯ QualitÃ© SQL: {quality_msg} (Score: {quality_score})")
            
            # 3. Tentative d'exÃ©cution
            start_exec = time.time()
            exec_result, columns = execute_sql_query(generated_sql)
            exec_time = time.time() - start_exec
            
            result['execution_time'] = round(exec_time, 2)
            
            # 4. VÃ©rification du rÃ©sultat
            if isinstance(exec_result, str) and "Erreur" in exec_result:
                result['execution_success'] = False
                result['error'] = exec_result
                print(f"\nâŒ ExÃ©cution Ã©chouÃ©e: {exec_result}")
            else:
                result['execution_success'] = True
                result['row_count'] = len(exec_result)
                result['columns'] = columns
                print(f"\nâœ… ExÃ©cution rÃ©ussie ({exec_time:.2f}s)")
                print(f"   Rows: {len(exec_result)} | Columns: {columns}")
                
                # Afficher un Ã©chantillon des rÃ©sultats
                if exec_result:
                    print(f"\nğŸ“Š Ã‰chantillon des rÃ©sultats:")
                    for i, row in enumerate(exec_result[:3]):
                        print(f"   {i+1}. {row}")
            
            # 5. Score global
            if result['execution_success'] and quality_score > 0:
                result['overall_score'] = 1.0
                result['status'] = "âœ… PASS"
            elif result['execution_success']:
                result['overall_score'] = 0.5
                result['status'] = "âš ï¸ PARTIAL"
            else:
                result['overall_score'] = 0.0
                result['status'] = "âŒ FAIL"
                
        except Exception as e:
            result['status'] = "âŒ ERROR"
            result['error'] = str(e)
            result['overall_score'] = 0.0
            print(f"\nğŸ’¥ Erreur inattendue: {e}")
        
        print(f"\n{'='*70}")
        print(f"RÃ©sultat: {result['status']} | Score: {result.get('overall_score', 0)}")
        print(f"{'='*70}\n")
        
        return result
    
    def run_all_tests(self):
        """Lance tous les tests SQL"""
        print("\n" + "ğŸš€ " * 30)
        print("DÃ‰MARRAGE DES TESTS SQL ENGINE")
        print("ğŸš€ " * 30)
        
        for test_case in self.questions:
            result = self.test_single_question(test_case)
            self.results.append(result)
            time.sleep(1)  # Pause entre les tests pour ne pas surcharger Ollama
        
        return self.generate_report()
    
    def generate_report(self):
        """GÃ©nÃ¨re un rapport dÃ©taillÃ©"""
        total = len(self.results)
        passed = sum(1 for r in self.results if r.get('overall_score', 0) == 1.0)
        partial = sum(1 for r in self.results if r.get('overall_score', 0) == 0.5)
        failed = sum(1 for r in self.results if r.get('overall_score', 0) == 0.0)
        
        avg_gen_time = sum(r.get('generation_time', 0) for r in self.results) / total
        avg_exec_time = sum(r.get('execution_time', 0) for r in self.results if 'execution_time' in r) / max(1, sum(1 for r in self.results if 'execution_time' in r))
        
        report = {
            'test_type': 'SQL Engine',
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_tests': total,
                'passed': passed,
                'partial': partial,
                'failed': failed,
                'success_rate': round((passed / total) * 100, 2) if total > 0 else 0,
                'avg_generation_time': round(avg_gen_time, 2),
                'avg_execution_time': round(avg_exec_time, 2)
            },
            'detailed_results': self.results
        }
        
        # Sauvegarde du rapport
        report_path = f"tests/results/sql_engine_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # Affichage du rÃ©sumÃ©
        print("\n" + "="*70)
        print("ğŸ“Š RAPPORT FINAL - SQL ENGINE")
        print("="*70)
        print(f"Total de tests: {total}")
        print(f"âœ… RÃ©ussis: {passed} ({report['summary']['success_rate']}%)")
        print(f"âš ï¸ Partiels: {partial}")
        print(f"âŒ Ã‰chouÃ©s: {failed}")
        print(f"\nâ±ï¸ Temps moyen de gÃ©nÃ©ration: {avg_gen_time:.2f}s")
        print(f"â±ï¸ Temps moyen d'exÃ©cution: {avg_exec_time:.2f}s")
        print(f"\nğŸ’¾ Rapport sauvegardÃ©: {report_path}")
        print("="*70 + "\n")
        
        return report


if __name__ == "__main__":
    tester = SQLEngineTest()
    tester.run_all_tests()
