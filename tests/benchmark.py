"""
Benchmark Global - Lance tous les tests et gÃ©nÃ¨re un rapport consolidÃ©
"""
import sys
import os
import json
import argparse
from datetime import datetime

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from test_router import RouterTest
from test_sql_engine import SQLEngineTest
from test_rag_engine import RAGEngineTest

class GlobalBenchmark:
    def __init__(self):
        self.reports = {}
        self.start_time = datetime.now()
    
    def run_router_tests(self):
        """Lance les tests du router"""
        print("\n" + "ğŸ¯"*30)
        print("PHASE 1/3 : TESTS ROUTER")
        print("ğŸ¯"*30 + "\n")
        tester = RouterTest()
        self.reports['router'] = tester.run_all_tests()
    
    def run_sql_tests(self):
        """Lance les tests SQL"""
        print("\n" + "ğŸ”§"*30)
        print("PHASE 2/3 : TESTS SQL ENGINE")
        print("ğŸ”§"*30 + "\n")
        tester = SQLEngineTest()
        self.reports['sql'] = tester.run_all_tests()
    
    def run_rag_tests(self):
        """Lance les tests RAG"""
        print("\n" + "ğŸ“š"*30)
        print("PHASE 3/3 : TESTS RAG ENGINE")
        print("ğŸ“š"*30 + "\n")
        tester = RAGEngineTest()
        self.reports['rag'] = tester.run_all_tests()
    
    def generate_consolidated_report(self):
        """GÃ©nÃ¨re un rapport consolidÃ© de tous les tests"""
        end_time = datetime.now()
        total_duration = (end_time - self.start_time).total_seconds()
        
        # Calcul des mÃ©triques globales
        consolidated = {
            'test_suite': 'Odoo Chatbot - Benchmark Global',
            'start_time': self.start_time.isoformat(),
            'end_time': end_time.isoformat(),
            'total_duration_seconds': round(total_duration, 2),
            'components': {
                'router': self.reports.get('router', {}).get('summary', {}),
                'sql_engine': self.reports.get('sql', {}).get('summary', {}),
                'rag_engine': self.reports.get('rag', {}).get('summary', {})
            },
            'global_metrics': self._calculate_global_metrics()
        }
        
        # Sauvegarde
        report_path = f"tests/results/benchmark_global_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(consolidated, f, indent=2, ensure_ascii=False)
        
        # Affichage
        self._print_consolidated_report(consolidated, report_path)
        
        return consolidated
    
    def _calculate_global_metrics(self):
        """Calcule les mÃ©triques globales"""
        metrics = {}
        
        # Router
        router_summary = self.reports.get('router', {}).get('summary', {})
        metrics['router_accuracy'] = router_summary.get('accuracy', 0)
        
        # SQL
        sql_summary = self.reports.get('sql', {}).get('summary', {})
        metrics['sql_success_rate'] = sql_summary.get('success_rate', 0)
        metrics['sql_avg_time'] = sql_summary.get('avg_generation_time', 0)
        
        # RAG
        rag_summary = self.reports.get('rag', {}).get('summary', {})
        metrics['rag_success_rate'] = rag_summary.get('success_rate', 0)
        metrics['rag_avg_quality'] = rag_summary.get('avg_quality_score', 0)
        metrics['rag_avg_time'] = rag_summary.get('avg_total_time', 0)
        
        # Score global (moyenne pondÃ©rÃ©e)
        metrics['global_score'] = round(
            (metrics['router_accuracy'] * 0.2 + 
             metrics['sql_success_rate'] * 0.4 + 
             metrics['rag_success_rate'] * 0.4) / 100,
            2
        )
        
        return metrics
    
    def _print_consolidated_report(self, report, path):
        """Affiche le rapport consolidÃ© de maniÃ¨re lisible"""
        print("\n" + "="*80)
        print("ğŸ“Š RAPPORT CONSOLIDÃ‰ - BENCHMARK GLOBAL")
        print("="*80)
        
        print(f"\nâ±ï¸  DurÃ©e totale: {report['total_duration_seconds']:.2f}s")
        print(f"ğŸ“… Date: {report['end_time']}")
        
        metrics = report['global_metrics']
        
        print(f"\n{'='*80}")
        print("ğŸ¯ MÃ‰TRIQUES GLOBALES")
        print(f"{'='*80}")
        print(f"Score Global: {metrics['global_score']}/1.0 ({metrics['global_score']*100:.1f}%)")
        
        print(f"\nğŸ“ ROUTER")
        print(f"   PrÃ©cision: {metrics['router_accuracy']:.2f}%")
        
        print(f"\nâš™ï¸  SQL ENGINE")
        print(f"   Taux de rÃ©ussite: {metrics['sql_success_rate']:.2f}%")
        print(f"   Temps moyen: {metrics['sql_avg_time']:.2f}s")
        
        print(f"\nğŸ“š RAG ENGINE")
        print(f"   Taux de rÃ©ussite: {metrics['rag_success_rate']:.2f}%")
        print(f"   QualitÃ© moyenne: {metrics['rag_avg_quality']:.2f}/1.0")
        print(f"   Temps moyen: {metrics['rag_avg_time']:.2f}s")
        
        print(f"\n{'='*80}")
        print(f"ğŸ’¾ Rapport complet sauvegardÃ©: {path}")
        print(f"{'='*80}\n")
    
    def run_full_benchmark(self, components=None):
        """
        Lance le benchmark complet ou seulement certains composants
        
        Args:
            components: Liste des composants Ã  tester ['router', 'sql', 'rag']
                       Si None, lance tous les tests
        """
        if components is None:
            components = ['router', 'sql', 'rag']
        
        print("\n" + "ğŸš€"*40)
        print("BENCHMARK GLOBAL - ODOO CHATBOT")
        print("ğŸš€"*40)
        print(f"Composants Ã  tester: {', '.join(components)}")
        print(f"DÃ©marrage: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print("ğŸš€"*40 + "\n")
        
        if 'router' in components:
            self.run_router_tests()
        
        if 'sql' in components:
            self.run_sql_tests()
        
        if 'rag' in components:
            self.run_rag_tests()
        
        return self.generate_consolidated_report()


def main():
    """Point d'entrÃ©e avec arguments CLI"""
    parser = argparse.ArgumentParser(description='Benchmark du Chatbot Odoo')
    parser.add_argument(
        '--components',
        nargs='+',
        choices=['router', 'sql', 'rag'],
        help='Composants Ã  tester (par dÃ©faut: tous)'
    )
    parser.add_argument(
        '--router-only',
        action='store_true',
        help='Tester uniquement le router'
    )
    parser.add_argument(
        '--sql-only',
        action='store_true',
        help='Tester uniquement le moteur SQL'
    )
    parser.add_argument(
        '--rag-only',
        action='store_true',
        help='Tester uniquement le moteur RAG'
    )
    
    args = parser.parse_args()
    
    # DÃ©terminer les composants Ã  tester
    components = None
    if args.router_only:
        components = ['router']
    elif args.sql_only:
        components = ['sql']
    elif args.rag_only:
        components = ['rag']
    elif args.components:
        components = args.components
    
    # Lancer le benchmark
    benchmark = GlobalBenchmark()
    benchmark.run_full_benchmark(components=components)


if __name__ == "__main__":
    main()
